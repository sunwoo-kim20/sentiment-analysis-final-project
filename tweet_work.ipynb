{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords \n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow import keras\n",
    "import string\n",
    "import re\n",
    "from sklearn.preprocessing import Normalizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "string.punctuation\n",
    "stop = stopwords.words('english')\n",
    "import deep_think"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    text_nopunct = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text_nopunct\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = re.split('\\W+', text)\n",
    "    return tokens\n",
    "\n",
    "def remove_stopwords(tokenized_list):\n",
    "    text = [word for word in tokenized_list if word not in stop]# To remove all stopwords\n",
    "    return text\n",
    "\n",
    "def lemmatizing(tokenized_text):\n",
    "    text = [wn.lemmatize(word) for word in tokenized_text]\n",
    "    return text\n",
    "\n",
    "def lema_tweet(df,column):\n",
    "    df['body_text_clean'] = df[column].apply(lambda x: remove_punct(x))\n",
    "    df['body_text_tokenized'] = df['body_text_clean'].apply(lambda x: tokenize(x.lower()))\n",
    "    df['body_text_nostop'] = df['body_text_tokenized'].apply(lambda x: remove_stopwords(x))\n",
    "    df['body_text_lemmatized'] = df['body_text_nostop'].apply(lambda x: lemmatizing(x))\n",
    "    it_list = []\n",
    "    for row in df['body_text_lemmatized']:\n",
    "        it_list.append(\" \".join(row))\n",
    "    df['joined_lemm'] = it_list\n",
    "    final_df = pd.DataFrame()\n",
    "    final_df['joined_lemm'] = df['joined_lemm'].iloc[:5000]\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"deep_sentiment_model_trained.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword1 = '(America OR USA OR United States of America)'\n",
    "keyword2 =  ' -is:retweet -is:reply lang:en'\n",
    "max_results = 10\n",
    "\n",
    "search_url = \"https://api.twitter.com/2/tweets/search/recent\"\n",
    "\n",
    "# US used as an example query as it is a required field\n",
    "query_params = {'query': keyword1+keyword2,\n",
    "                'max_results': max_results,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_dict = [{'tweet': 'Well goodnight guys. I have to go now. Just remember tonight as you lay in bed. Youâ€™re worrying about economic security and work and such. Just remember this and you will be okay. Itâ€™s a mantra. America is back! America is back baby!ðŸ‡ºðŸ‡¸ https://t.co/9kjO2qotU5',\n",
    "  'sentiment score': ''},\n",
    " {'tweet': 'If they do not amend this bill I will be leaving the USA and running nodes elsewhere. #crypto https://t.co/etI4PRx88X',\n",
    "  'sentiment score': ''},\n",
    " {'tweet': '#vacation - Best things to do in Richmond - United States of America https://t.co/Ioj60LgYTo',\n",
    "  'sentiment score': ''},\n",
    " {'tweet': '$BTC.X $ETH.X $XRP.X America Is Behind on Cryptocurrency Adoption: Report https://t.co/Qwz2lDyRne https://t.co/Cv3EpDx1E3',\n",
    "  'sentiment score': ''},\n",
    " {'tweet': '#vacation - Amazing spots to visit in Richmond, United States of America https://t.co/vRr93O1yJ8',\n",
    "  'sentiment score': ''},\n",
    " {'tweet': 'weve been waiting 2 hours in the fucking ER. FUCK AMERICA \\nmy mom has symptoms of appendicitis and weve been sitting here for 2 hours (not vounting the 2 other hours at the clinic before we got told to come to the ER) \\nthe American healthcare system leaves people to die',\n",
    "  'sentiment score': ''},\n",
    " {'tweet': '#tour - Awesome attractions to enjoy in Richmond (United States of America) https://t.co/mvif4antZm',\n",
    "  'sentiment score': ''},\n",
    " {'tweet': 'People in #CostaRica live longer than in the #USA Also, Costa Rica has no army. Coincidence? https://t.co/zGppp3UV8v',\n",
    "  'sentiment score': ''},\n",
    " {'tweet': 'Black America spread the word-- Dan Patrick Blames Black-People For-Surge https://t.co/CYCixVYcB2 via @YouTube',\n",
    "  'sentiment score': ''},\n",
    " {'tweet': 'Some digital divides persist between rural, urban and suburban America https://t.co/4lxtdV68dP https://t.co/AMHFYJiUvZ',\n",
    "  'sentiment score': ''}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df['tweet'] = [tweet_dict[5]['tweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = lema_tweet(tweet_df,'tweet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = export_vector.transform(tweet_df['joined_lemm']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweeter = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.45663303]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
